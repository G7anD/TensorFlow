{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cal_housing_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = data.drop(columns=['medianHouseValue'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  \n",
       "0        8.3252  \n",
       "1        8.3014  \n",
       "2        7.2574  \n",
       "3        5.6431  \n",
       "4        3.8462  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452600.0\n",
       "1    358500.0\n",
       "2    352100.0\n",
       "3    341300.0\n",
       "4    342200.0\n",
       "Name: medianHouseValue, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['medianHouseValue']\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data, labels, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14448.000000</td>\n",
       "      <td>14448.000000</td>\n",
       "      <td>14448.000000</td>\n",
       "      <td>14448.000000</td>\n",
       "      <td>14448.000000</td>\n",
       "      <td>14448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.541534</td>\n",
       "      <td>0.067050</td>\n",
       "      <td>0.083377</td>\n",
       "      <td>0.049882</td>\n",
       "      <td>0.082078</td>\n",
       "      <td>0.232512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.246886</td>\n",
       "      <td>0.056436</td>\n",
       "      <td>0.066473</td>\n",
       "      <td>0.039699</td>\n",
       "      <td>0.063839</td>\n",
       "      <td>0.130034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.045624</td>\n",
       "      <td>0.027448</td>\n",
       "      <td>0.045716</td>\n",
       "      <td>0.142934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.054046</td>\n",
       "      <td>0.067272</td>\n",
       "      <td>0.040682</td>\n",
       "      <td>0.067259</td>\n",
       "      <td>0.209138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.080122</td>\n",
       "      <td>0.100287</td>\n",
       "      <td>0.060113</td>\n",
       "      <td>0.099326</td>\n",
       "      <td>0.293106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge    totalRooms  totalBedrooms    population  \\\n",
       "count      14448.000000  14448.000000   14448.000000  14448.000000   \n",
       "mean           0.541534      0.067050       0.083377      0.049882   \n",
       "std            0.246886      0.056436       0.066473      0.039699   \n",
       "min            0.000000      0.000000       0.000000      0.000000   \n",
       "25%            0.333333      0.036650       0.045624      0.027448   \n",
       "50%            0.549020      0.054046       0.067272      0.040682   \n",
       "75%            0.705882      0.080122       0.100287      0.060113   \n",
       "max            1.000000      1.000000       1.000000      1.000000   \n",
       "\n",
       "         households  medianIncome  \n",
       "count  14448.000000  14448.000000  \n",
       "mean       0.082078      0.232512  \n",
       "std        0.063839      0.130034  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.045716      0.142934  \n",
       "50%        0.067259      0.209138  \n",
       "75%        0.099326      0.293106  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='housingMedianAge', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='totalRooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='totalBedrooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='population', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='households', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='medianIncome', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fnc = tf.estimator.inputs.pandas_input_fn(X_train, y_train, batch_size=10, num_epochs=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprcu17nvz\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmprcu17nvz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff114c629e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNRegressor(hidden_units=[6,6,6], feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/grand/.conda/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/grand/.conda/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/grand/.conda/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/grand/.conda/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/grand/.conda/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmprcu17nvz/model.ckpt.\n",
      "INFO:tensorflow:loss = 438311160000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 59.1689\n",
      "INFO:tensorflow:loss = 217467750000.0, step = 101 (1.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.519\n",
      "INFO:tensorflow:loss = 360868600000.0, step = 201 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.518\n",
      "INFO:tensorflow:loss = 251214940000.0, step = 301 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.639\n",
      "INFO:tensorflow:loss = 787194900000.0, step = 401 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.151\n",
      "INFO:tensorflow:loss = 661484500000.0, step = 501 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.736\n",
      "INFO:tensorflow:loss = 477206250000.0, step = 601 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.192\n",
      "INFO:tensorflow:loss = 440551100000.0, step = 701 (0.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.874\n",
      "INFO:tensorflow:loss = 521779540000.0, step = 801 (0.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.397\n",
      "INFO:tensorflow:loss = 368206480000.0, step = 901 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.276\n",
      "INFO:tensorflow:loss = 407830130000.0, step = 1001 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.482\n",
      "INFO:tensorflow:loss = 223798210000.0, step = 1101 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.143\n",
      "INFO:tensorflow:loss = 203838930000.0, step = 1201 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.665\n",
      "INFO:tensorflow:loss = 328120830000.0, step = 1301 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.538\n",
      "INFO:tensorflow:loss = 390672420000.0, step = 1401 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.396\n",
      "INFO:tensorflow:loss = 98724676000.0, step = 1501 (0.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.637\n",
      "INFO:tensorflow:loss = 152800410000.0, step = 1601 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.752\n",
      "INFO:tensorflow:loss = 265628140000.0, step = 1701 (0.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.167\n",
      "INFO:tensorflow:loss = 380337850000.0, step = 1801 (0.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.982\n",
      "INFO:tensorflow:loss = 46881840000.0, step = 1901 (0.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.289\n",
      "INFO:tensorflow:loss = 165208670000.0, step = 2001 (0.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.631\n",
      "INFO:tensorflow:loss = 66499265000.0, step = 2101 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.879\n",
      "INFO:tensorflow:loss = 208910580000.0, step = 2201 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.43\n",
      "INFO:tensorflow:loss = 149080200000.0, step = 2301 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.475\n",
      "INFO:tensorflow:loss = 49577116000.0, step = 2401 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.487\n",
      "INFO:tensorflow:loss = 32440398000.0, step = 2501 (0.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.632\n",
      "INFO:tensorflow:loss = 42033013000.0, step = 2601 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.031\n",
      "INFO:tensorflow:loss = 68089270000.0, step = 2701 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.08\n",
      "INFO:tensorflow:loss = 36698870000.0, step = 2801 (0.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.248\n",
      "INFO:tensorflow:loss = 168524760000.0, step = 2901 (0.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.395\n",
      "INFO:tensorflow:loss = 116845720000.0, step = 3001 (0.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.273\n",
      "INFO:tensorflow:loss = 65641730000.0, step = 3101 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.656\n",
      "INFO:tensorflow:loss = 100524670000.0, step = 3201 (0.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.145\n",
      "INFO:tensorflow:loss = 138745090000.0, step = 3301 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.042\n",
      "INFO:tensorflow:loss = 134646240000.0, step = 3401 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.61\n",
      "INFO:tensorflow:loss = 37945876000.0, step = 3501 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.217\n",
      "INFO:tensorflow:loss = 132792980000.0, step = 3601 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.191\n",
      "INFO:tensorflow:loss = 102547010000.0, step = 3701 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.216\n",
      "INFO:tensorflow:loss = 91771980000.0, step = 3801 (0.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.867\n",
      "INFO:tensorflow:loss = 188220850000.0, step = 3901 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.602\n",
      "INFO:tensorflow:loss = 58209220000.0, step = 4001 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.305\n",
      "INFO:tensorflow:loss = 106393210000.0, step = 4101 (0.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.14\n",
      "INFO:tensorflow:loss = 82683210000.0, step = 4201 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.606\n",
      "INFO:tensorflow:loss = 71371640000.0, step = 4301 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.635\n",
      "INFO:tensorflow:loss = 150428120000.0, step = 4401 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.354\n",
      "INFO:tensorflow:loss = 116922920000.0, step = 4501 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.093\n",
      "INFO:tensorflow:loss = 117575500000.0, step = 4601 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.92\n",
      "INFO:tensorflow:loss = 160980170000.0, step = 4701 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.393\n",
      "INFO:tensorflow:loss = 62420996000.0, step = 4801 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.064\n",
      "INFO:tensorflow:loss = 119935530000.0, step = 4901 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.293\n",
      "INFO:tensorflow:loss = 219869640000.0, step = 5001 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.233\n",
      "INFO:tensorflow:loss = 54089912000.0, step = 5101 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.318\n",
      "INFO:tensorflow:loss = 95647340000.0, step = 5201 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.444\n",
      "INFO:tensorflow:loss = 139516310000.0, step = 5301 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.173\n",
      "INFO:tensorflow:loss = 55380130000.0, step = 5401 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.15\n",
      "INFO:tensorflow:loss = 156394650000.0, step = 5501 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.331\n",
      "INFO:tensorflow:loss = 210672800000.0, step = 5601 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.698\n",
      "INFO:tensorflow:loss = 161447720000.0, step = 5701 (0.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.522\n",
      "INFO:tensorflow:loss = 176353440000.0, step = 5801 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.254\n",
      "INFO:tensorflow:loss = 114136590000.0, step = 5901 (0.576 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 174.388\n",
      "INFO:tensorflow:loss = 97951200000.0, step = 6001 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.206\n",
      "INFO:tensorflow:loss = 115242615000.0, step = 6101 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.758\n",
      "INFO:tensorflow:loss = 238274950000.0, step = 6201 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.267\n",
      "INFO:tensorflow:loss = 98836595000.0, step = 6301 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.778\n",
      "INFO:tensorflow:loss = 81143185000.0, step = 6401 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.642\n",
      "INFO:tensorflow:loss = 122415735000.0, step = 6501 (0.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.514\n",
      "INFO:tensorflow:loss = 180075870000.0, step = 6601 (0.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.571\n",
      "INFO:tensorflow:loss = 117714380000.0, step = 6701 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.336\n",
      "INFO:tensorflow:loss = 176658730000.0, step = 6801 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.773\n",
      "INFO:tensorflow:loss = 145261000000.0, step = 6901 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.067\n",
      "INFO:tensorflow:loss = 50980348000.0, step = 7001 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.542\n",
      "INFO:tensorflow:loss = 101723260000.0, step = 7101 (0.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.314\n",
      "INFO:tensorflow:loss = 56177320000.0, step = 7201 (0.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.088\n",
      "INFO:tensorflow:loss = 225967370000.0, step = 7301 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.204\n",
      "INFO:tensorflow:loss = 126762640000.0, step = 7401 (0.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.2\n",
      "INFO:tensorflow:loss = 104960860000.0, step = 7501 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.951\n",
      "INFO:tensorflow:loss = 41400934000.0, step = 7601 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.102\n",
      "INFO:tensorflow:loss = 77182580000.0, step = 7701 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.973\n",
      "INFO:tensorflow:loss = 143792400000.0, step = 7801 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.136\n",
      "INFO:tensorflow:loss = 195915760000.0, step = 7901 (0.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.111\n",
      "INFO:tensorflow:loss = 55478610000.0, step = 8001 (0.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.014\n",
      "INFO:tensorflow:loss = 75618440000.0, step = 8101 (0.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.496\n",
      "INFO:tensorflow:loss = 54906524000.0, step = 8201 (0.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.228\n",
      "INFO:tensorflow:loss = 83085840000.0, step = 8301 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.433\n",
      "INFO:tensorflow:loss = 144108850000.0, step = 8401 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.034\n",
      "INFO:tensorflow:loss = 78870815000.0, step = 8501 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.606\n",
      "INFO:tensorflow:loss = 87085195000.0, step = 8601 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.626\n",
      "INFO:tensorflow:loss = 181345700000.0, step = 8701 (0.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4803\n",
      "INFO:tensorflow:loss = 146566580000.0, step = 8801 (1.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.393\n",
      "INFO:tensorflow:loss = 118450810000.0, step = 8901 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.657\n",
      "INFO:tensorflow:loss = 181265270000.0, step = 9001 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9278\n",
      "INFO:tensorflow:loss = 148352760000.0, step = 9101 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.6223\n",
      "INFO:tensorflow:loss = 149824440000.0, step = 9201 (1.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.5855\n",
      "INFO:tensorflow:loss = 104428100000.0, step = 9301 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.184\n",
      "INFO:tensorflow:loss = 235917480000.0, step = 9401 (0.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.346\n",
      "INFO:tensorflow:loss = 164357960000.0, step = 9501 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.939\n",
      "INFO:tensorflow:loss = 116569660000.0, step = 9601 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8269\n",
      "INFO:tensorflow:loss = 70010356000.0, step = 9701 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.24\n",
      "INFO:tensorflow:loss = 57105680000.0, step = 9801 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.4783\n",
      "INFO:tensorflow:loss = 78652540000.0, step = 9901 (1.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.126\n",
      "INFO:tensorflow:loss = 64961670000.0, step = 10001 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.673\n",
      "INFO:tensorflow:loss = 66187858000.0, step = 10101 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.227\n",
      "INFO:tensorflow:loss = 113741360000.0, step = 10201 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.687\n",
      "INFO:tensorflow:loss = 115403240000.0, step = 10301 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.731\n",
      "INFO:tensorflow:loss = 191885310000.0, step = 10401 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.716\n",
      "INFO:tensorflow:loss = 205338970000.0, step = 10501 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.051\n",
      "INFO:tensorflow:loss = 124435690000.0, step = 10601 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.075\n",
      "INFO:tensorflow:loss = 94200740000.0, step = 10701 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.868\n",
      "INFO:tensorflow:loss = 130242100000.0, step = 10801 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.771\n",
      "INFO:tensorflow:loss = 68879850000.0, step = 10901 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.321\n",
      "INFO:tensorflow:loss = 235641850000.0, step = 11001 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.67\n",
      "INFO:tensorflow:loss = 32031054000.0, step = 11101 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.391\n",
      "INFO:tensorflow:loss = 43276874000.0, step = 11201 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.553\n",
      "INFO:tensorflow:loss = 107116440000.0, step = 11301 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.06\n",
      "INFO:tensorflow:loss = 177077780000.0, step = 11401 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.013\n",
      "INFO:tensorflow:loss = 98429600000.0, step = 11501 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.374\n",
      "INFO:tensorflow:loss = 52614005000.0, step = 11601 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.789\n",
      "INFO:tensorflow:loss = 71174210000.0, step = 11701 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.135\n",
      "INFO:tensorflow:loss = 138424010000.0, step = 11801 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.508\n",
      "INFO:tensorflow:loss = 94413185000.0, step = 11901 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.979\n",
      "INFO:tensorflow:loss = 46433500000.0, step = 12001 (0.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.1261\n",
      "INFO:tensorflow:loss = 59944880000.0, step = 12101 (1.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.1771\n",
      "INFO:tensorflow:loss = 188922230000.0, step = 12201 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.571\n",
      "INFO:tensorflow:loss = 90407640000.0, step = 12301 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.725\n",
      "INFO:tensorflow:loss = 34490524000.0, step = 12401 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.547\n",
      "INFO:tensorflow:loss = 139855540000.0, step = 12501 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.5042\n",
      "INFO:tensorflow:loss = 36833956000.0, step = 12601 (1.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.6871\n",
      "INFO:tensorflow:loss = 76946340000.0, step = 12701 (1.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2488\n",
      "INFO:tensorflow:loss = 37228077000.0, step = 12801 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2881\n",
      "INFO:tensorflow:loss = 67430138000.0, step = 12901 (1.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6897\n",
      "INFO:tensorflow:loss = 147071340000.0, step = 13001 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3373\n",
      "INFO:tensorflow:loss = 183375170000.0, step = 13101 (1.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1498\n",
      "INFO:tensorflow:loss = 55550345000.0, step = 13201 (1.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.7825\n",
      "INFO:tensorflow:loss = 87431570000.0, step = 13301 (1.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7658\n",
      "INFO:tensorflow:loss = 91597720000.0, step = 13401 (1.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.204\n",
      "INFO:tensorflow:loss = 84446240000.0, step = 13501 (1.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.4914\n",
      "INFO:tensorflow:loss = 121718710000.0, step = 13601 (1.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.6505\n",
      "INFO:tensorflow:loss = 75631740000.0, step = 13701 (1.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9529\n",
      "INFO:tensorflow:loss = 123033980000.0, step = 13801 (1.121 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 178.366\n",
      "INFO:tensorflow:loss = 102782970000.0, step = 13901 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.0448\n",
      "INFO:tensorflow:loss = 208033500000.0, step = 14001 (1.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.348\n",
      "INFO:tensorflow:loss = 89367540000.0, step = 14101 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.071\n",
      "INFO:tensorflow:loss = 103353140000.0, step = 14201 (0.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.0963\n",
      "INFO:tensorflow:loss = 148688320000.0, step = 14301 (1.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.966\n",
      "INFO:tensorflow:loss = 158759960000.0, step = 14401 (0.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.345\n",
      "INFO:tensorflow:loss = 100624420000.0, step = 14501 (1.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.212\n",
      "INFO:tensorflow:loss = 143556070000.0, step = 14601 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.897\n",
      "INFO:tensorflow:loss = 159631380000.0, step = 14701 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.894\n",
      "INFO:tensorflow:loss = 58961910000.0, step = 14801 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.139\n",
      "INFO:tensorflow:loss = 194353600000.0, step = 14901 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.166\n",
      "INFO:tensorflow:loss = 73868340000.0, step = 15001 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.228\n",
      "INFO:tensorflow:loss = 61952780000.0, step = 15101 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.194\n",
      "INFO:tensorflow:loss = 18870346000.0, step = 15201 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.91\n",
      "INFO:tensorflow:loss = 86236365000.0, step = 15301 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.366\n",
      "INFO:tensorflow:loss = 132005510000.0, step = 15401 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.779\n",
      "INFO:tensorflow:loss = 72762300000.0, step = 15501 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.861\n",
      "INFO:tensorflow:loss = 64430840000.0, step = 15601 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.542\n",
      "INFO:tensorflow:loss = 119179770000.0, step = 15701 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.605\n",
      "INFO:tensorflow:loss = 46325395000.0, step = 15801 (0.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.779\n",
      "INFO:tensorflow:loss = 35997254000.0, step = 15901 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.002\n",
      "INFO:tensorflow:loss = 119594650000.0, step = 16001 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.4818\n",
      "INFO:tensorflow:loss = 52894654000.0, step = 16101 (1.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.578\n",
      "INFO:tensorflow:loss = 96528290000.0, step = 16201 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.339\n",
      "INFO:tensorflow:loss = 67830670000.0, step = 16301 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.995\n",
      "INFO:tensorflow:loss = 245923380000.0, step = 16401 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.202\n",
      "INFO:tensorflow:loss = 147998800000.0, step = 16501 (0.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.76\n",
      "INFO:tensorflow:loss = 190426150000.0, step = 16601 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.119\n",
      "INFO:tensorflow:loss = 34252063000.0, step = 16701 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.43\n",
      "INFO:tensorflow:loss = 65803977000.0, step = 16801 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.506\n",
      "INFO:tensorflow:loss = 101286820000.0, step = 16901 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.187\n",
      "INFO:tensorflow:loss = 90818560000.0, step = 17001 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.72\n",
      "INFO:tensorflow:loss = 98397970000.0, step = 17101 (1.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.278\n",
      "INFO:tensorflow:loss = 152682920000.0, step = 17201 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.091\n",
      "INFO:tensorflow:loss = 113863060000.0, step = 17301 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.514\n",
      "INFO:tensorflow:loss = 65050923000.0, step = 17401 (0.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3984\n",
      "INFO:tensorflow:loss = 115266030000.0, step = 17501 (1.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.291\n",
      "INFO:tensorflow:loss = 109770040000.0, step = 17601 (1.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.232\n",
      "INFO:tensorflow:loss = 78229040000.0, step = 17701 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.11\n",
      "INFO:tensorflow:loss = 68605420000.0, step = 17801 (1.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.2613\n",
      "INFO:tensorflow:loss = 70682020000.0, step = 17901 (1.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.19\n",
      "INFO:tensorflow:loss = 55502990000.0, step = 18001 (1.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.21\n",
      "INFO:tensorflow:loss = 134730230000.0, step = 18101 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5338\n",
      "INFO:tensorflow:loss = 89015530000.0, step = 18201 (1.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.4524\n",
      "INFO:tensorflow:loss = 177270600000.0, step = 18301 (1.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5812\n",
      "INFO:tensorflow:loss = 66605613000.0, step = 18401 (1.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.199\n",
      "INFO:tensorflow:loss = 86068855000.0, step = 18501 (0.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.366\n",
      "INFO:tensorflow:loss = 112120455000.0, step = 18601 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.645\n",
      "INFO:tensorflow:loss = 49052066000.0, step = 18701 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.184\n",
      "INFO:tensorflow:loss = 219793500000.0, step = 18801 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.366\n",
      "INFO:tensorflow:loss = 82513460000.0, step = 18901 (0.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.7613\n",
      "INFO:tensorflow:loss = 88938100000.0, step = 19001 (1.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.086\n",
      "INFO:tensorflow:loss = 60079514000.0, step = 19101 (0.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.73\n",
      "INFO:tensorflow:loss = 151311960000.0, step = 19201 (0.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.479\n",
      "INFO:tensorflow:loss = 65244520000.0, step = 19301 (0.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.387\n",
      "INFO:tensorflow:loss = 140271980000.0, step = 19401 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.636\n",
      "INFO:tensorflow:loss = 113556080000.0, step = 19501 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.118\n",
      "INFO:tensorflow:loss = 75920980000.0, step = 19601 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.321\n",
      "INFO:tensorflow:loss = 85891060000.0, step = 19701 (0.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.244\n",
      "INFO:tensorflow:loss = 131165860000.0, step = 19801 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.59\n",
      "INFO:tensorflow:loss = 118998740000.0, step = 19901 (0.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.9673\n",
      "INFO:tensorflow:loss = 81425210000.0, step = 20001 (1.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.46\n",
      "INFO:tensorflow:loss = 128625850000.0, step = 20101 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.844\n",
      "INFO:tensorflow:loss = 101461410000.0, step = 20201 (0.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.1077\n",
      "INFO:tensorflow:loss = 86928474000.0, step = 20301 (1.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9887\n",
      "INFO:tensorflow:loss = 70229130000.0, step = 20401 (1.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2548\n",
      "INFO:tensorflow:loss = 35744375000.0, step = 20501 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.6313\n",
      "INFO:tensorflow:loss = 217375650000.0, step = 20601 (1.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.3768\n",
      "INFO:tensorflow:loss = 63758290000.0, step = 20701 (1.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.8285\n",
      "INFO:tensorflow:loss = 67077698000.0, step = 20801 (1.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.3844\n",
      "INFO:tensorflow:loss = 138743450000.0, step = 20901 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4524\n",
      "INFO:tensorflow:loss = 110488660000.0, step = 21001 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.481\n",
      "INFO:tensorflow:loss = 48838492000.0, step = 21101 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.125\n",
      "INFO:tensorflow:loss = 94521460000.0, step = 21201 (0.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3841\n",
      "INFO:tensorflow:loss = 120928166000.0, step = 21301 (1.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.0346\n",
      "INFO:tensorflow:loss = 88161430000.0, step = 21401 (1.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7609\n",
      "INFO:tensorflow:loss = 56523620000.0, step = 21501 (1.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.4324\n",
      "INFO:tensorflow:loss = 36433290000.0, step = 21601 (1.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.9143\n",
      "INFO:tensorflow:loss = 65809084000.0, step = 21701 (1.035 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 108.756\n",
      "INFO:tensorflow:loss = 181501250000.0, step = 21801 (0.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6073\n",
      "INFO:tensorflow:loss = 125284246000.0, step = 21901 (1.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.7807\n",
      "INFO:tensorflow:loss = 73642250000.0, step = 22001 (1.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5951\n",
      "INFO:tensorflow:loss = 217478270000.0, step = 22101 (1.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.111\n",
      "INFO:tensorflow:loss = 48913523000.0, step = 22201 (0.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8327\n",
      "INFO:tensorflow:loss = 116317100000.0, step = 22301 (1.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.024\n",
      "INFO:tensorflow:loss = 24518513000.0, step = 22401 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.6882\n",
      "INFO:tensorflow:loss = 105702900000.0, step = 22501 (1.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7319\n",
      "INFO:tensorflow:loss = 46104633000.0, step = 22601 (1.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3944\n",
      "INFO:tensorflow:loss = 105157930000.0, step = 22701 (1.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0715\n",
      "INFO:tensorflow:loss = 198456670000.0, step = 22801 (1.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.6561\n",
      "INFO:tensorflow:loss = 120087150000.0, step = 22901 (1.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.5182\n",
      "INFO:tensorflow:loss = 82507465000.0, step = 23001 (1.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.7102\n",
      "INFO:tensorflow:loss = 51904225000.0, step = 23101 (1.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.0199\n",
      "INFO:tensorflow:loss = 79569510000.0, step = 23201 (1.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3697\n",
      "INFO:tensorflow:loss = 39806403000.0, step = 23301 (1.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8166\n",
      "INFO:tensorflow:loss = 106100090000.0, step = 23401 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.232\n",
      "INFO:tensorflow:loss = 61471216000.0, step = 23501 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5864\n",
      "INFO:tensorflow:loss = 60984550000.0, step = 23601 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0704\n",
      "INFO:tensorflow:loss = 191456180000.0, step = 23701 (1.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.4466\n",
      "INFO:tensorflow:loss = 244518350000.0, step = 23801 (1.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.6871\n",
      "INFO:tensorflow:loss = 101356830000.0, step = 23901 (1.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.9891\n",
      "INFO:tensorflow:loss = 38258827000.0, step = 24001 (1.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0599\n",
      "INFO:tensorflow:loss = 86359330000.0, step = 24101 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9521\n",
      "INFO:tensorflow:loss = 97496040000.0, step = 24201 (1.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.8124\n",
      "INFO:tensorflow:loss = 120226546000.0, step = 24301 (1.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5498\n",
      "INFO:tensorflow:loss = 90405880000.0, step = 24401 (1.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.124\n",
      "INFO:tensorflow:loss = 127457150000.0, step = 24501 (1.346 sec)\n"
     ]
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_fnc, steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_fn = tf.estimator.inputs.pandas_input_fn(X_test, y_test, batch_size=10, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = dnn_model.predict(pred_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(prediction)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in predictions:\n",
    "    pred.append(i['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
